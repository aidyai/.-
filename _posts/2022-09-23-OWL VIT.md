# 100: OWL VIT
## Simple Open-Vocabulary Object Detection with Vision Transformers.

## ABSTRACT.
![[OWL VIT.PNG]]

#### GOAL: 
	The goal of the Paper is to create a Simple & Scalable Open-Vocabulary Object Detector. The method is called Vision Transformer for Open-World Localization (OWL-VIT)
	
#### Motivation:
	Considering that Object Detection is a fundamental task in Computer Vision, the state of Object Detection models until recently have been such that it is only limited to a small, fixed set of semantic categories because obtaining localized training data with large or open label spaces have proven problematic as it relates to cost and time consumption as such a technique that incoporates open world vocabulary as semantic categories is needful.
	 Additionally in Object Detection, pretraining and Scaling approcahes are less well established, especially in long-tailed and open vocabulary setting, where training data is relatively scarce.

#### Solution:
![[OWL VIT1.PNG]] 


	Things have taken the turn for the better because of the development of powerful Architectures that have achieved remarkable feats in Contrsative Image-Text Training as well as Text Encoding. 
	
	The Authors solved the problem by creating a modular, scalable, simple and flexible Architecture which consists of Two SOTA Transformer Encoders for Vision and Text and the reason for a Transformers based model is because of its scalability and previous success in closed-vocabulary detection.

![[OWL VIT2.PNG]]

	It is modular because the image and text Encoders are not yoked together, scalable as a result of performance increase in detection even though model size and pretraining time is increased, flexible because this same model can be used for image-conditioned one-shot detection.	
	The Architecture works for open vocalulary object detection even on categories not seen during training as a result of the models two stage recipe below:
		A. Pre-training of the image and text encoder on 2million Image-Text pairs contrastively.
		B. Configuring our Pretrained Image encoders to Open Vocabulary Object Detection by removing the token pooling and unifying it with light-weight object classification and localization heads directly to the image encoder output tokens. 

![[OWL VIT4.PNG]]



#### Concepts [RELATED]:
	1. Contrastive Vision-Language Pre-Training
	2. Closed-Vocabulary Object Detection
	3. Long-Tailed and Open-Vocabulary Object Detection
	4. Image-Conditioned Detection


#### Concepts [MAIN]:

	1. Open-vocabulary object detection
	2. One- or Few-Shot Transfer.
	3. Detector Training 
	4. Image-Level Contrastive Pre-Training

#### Experiments

#### Links:
	https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit







#### PYTORCH PROJECT
	Open Vocabulary UI ELEMNETS DETECTION in Figma
#### Check Out This Other Paper with Code

